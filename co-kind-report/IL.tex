\section{Intermediate Language}~\label{sec:il}

Each prover first translates the Copilot specification into an
intermediate representation best suited for model checking. Two
representations are available :

\begin{itemize}
\item
  The \textbf{IL} format : a list
  of quantifier-free equations over integer sequences, implicitly
  universally quantified by a free variable \emph{n}. Each sequence
  roughly corresponds to a stream. This format is the one used in G.
  Hagen's thesis~\cite{HagenPhD}. The \emph{light prover} works with this
  format.
\item
  The \textbf{TransSys} format : a modular representation of a \emph{state transition system}~\cite{XX} The \emph{Kind2 prover} uses thisitio
  format, which is similar to Kind2's native format.
\end{itemize}

\textbf{Cnub} is a simplified representation of a Copilot program where
only the informations useful for SMT-based model checking are kept. For
now, it is not used by the two standard provers but it could be used in
the future as an intermediate step in the translation of a copilot specification to the \textbf{IL} or \textbf{TransSys} format.



%For each of these formats, there is a folder in
%\texttt{src/Copilot/Kind} which contains at least three files

%\begin{itemize}
%\item \texttt{Spec.hs} where the format is defined
%\item \texttt{PrettyPrint.hs} for pretty
%printing (useful for debugging) 
%\item \texttt{Translate.hs} where the
%translation process from \texttt{Core.Spec} is defined
%\end{itemize}

%These three formats share a simplified set of types and operators,
%defined respectively in \texttt{Misc.Type} and \texttt{Misc.Operator}.


\subsection{The \textbf{Cnub} format}

The complexity of the models that are built from Copilot specification is limited by the power and expressiveness of the theories handled by the current SMT solver. For instance, bounded integer arithmetic is often approximated by standard integer arithmetic as overflow problems are ignored and most real functions like trigonometric functions are not handled.

The \textbf{Cnub} format is aimed at abstracting a copilot specification in a format relying on a simple theory including basic integer and real arithmetic and uninterpreted functions. As said before, using it as an intermediate step in the translation process to \textbf{IL} or \textbf{TransSys} would result in a significant simplification of the latter.


In the \textbf{Cnub} format, the stream structure is kept from the copilot core. However, the following differences have to be emphasized :

\begin{itemize}
\item In contrast to the great diversity of numeric types available in Copilot, we restrain ourselves to three basic types which are handled by the \texttt{SMTLib} standard and defined in \texttt{Kind.Misc.Types} : \texttt{Bool}, \texttt{Integer} and \texttt{Real}.


\item \textit{Uninterpreted functions} are used to model operators that are not handled. Uninterpreted functions are abstract symbols with the property that : $$ \left( \forall i . \; x_i = y_i \right) \Longrightarrow f(x_1, \cdots, x_n) = f(y_1, \cdots, y_n). $$ They are provided by most SMT solvers.

\item \textit{Non-deterministic} functions are used to deal with extern values, which corresponds to the copilot constructions \texttt{ExternFun}, \texttt{ExternVar} and \texttt{ExternArray}. They could be seen as uninterpreted functions taking as an additional argument the current time. Indeed, between two clock ticks, they yield the same result if given the same argument. However, they can change at each clock tick.

\end{itemize}


\paragraph{Remark : some ideas to build more faithful models}

Treating machine integers as unbounded integers and complex operators as uninterpreted functions might be an unacceptable approximation in many cases. The first problem could be tackled by adding automatically to the property being verified some bound-checking conditions for all integer variables. This solution has many weaknesses :

\begin{itemize}
\item It treats every program which causes an integer overflow as wrong, although this behaviour could be intended.
\item It generates a great overhead for the proof engine.
\end{itemize}

An intermediate solution could be to let the developper annotate the program so he can specify which bounds have to be checked automatically.


\medskip

The problem of complex operators like trigonometry operators is more difficult to handle. A seemingly good solution would be to give some classical properties of these operators as additional constraints for the SMT solvers. For instance, we could add the following constraint to any specification where the sine function appears : \[ \forall x . \; -1 \leq \sin x \leq 1 \]

Unfortunately, quantifiers are not handled well by the current state
of the art SMT solvers.~\footnote{As we will discuss it later, it
  seems to us it is one of the main limitation of SMT-based techniques
  which keeps them from scaling well.} An alternative would be to add
automatically a specialized version of these constraints for each
appropriate variable. For instance, we could add the constraint \[-1
\leq y \leq 1 \] for all variables $y$ such that we have a
constraint \[ y = \sin x \] for $x$ any variable.  Further
improvements on these techniques warrant further study.





\subsection{The \textbf{IL} format}

In this format, a stream of type $a$ is modeled by a function of type $\mathbb{N} \to a$. Each stream definition is translated into a list of constraints on such functions. For instance, the stream definition :
\begin{lstlisting}[frame=single]
fib = [1, 1] ++ (fib + drop 1 fib)
\end{lstlisting}
is translated into a function $f : \mathbb{N} \to \mathbb{N}$ with the constraints :
$$
\begin{array}{c}
f(0) = 1 \\
f(1) = 1 \\
\forall n . \; f(n + 2) = f(n + 1) + f(n)
\end{array}
$$

\medskip

Specifications in the \textbf{IL} format can be printed out in the SMTLib format.

\paragraph{The translation process} 

The translation process is straightforward as the reification process~\cite{gill,pike-icfp-12} has previously transformed the copilot program such that the \texttt{(++)} operator only occurs at the top of a stream definition. Indeed, all stream definitions are written with the pattern
\begin{center}\texttt{ s = [$s_0$,...,$s_p$] ++ e}\end{center}
where \texttt{e} is an expression in which \texttt{(++)} does not occur. In \texttt{Core.Spec}, a stream is defined as :
\begin{lstlisting}[frame=single]
data Stream = forall a.Typed a => Stream
  { streamId         :: Id
  , streamBuffer     :: [a]
  , streamExpr       :: Expr a
  , streamExprType   :: Type a }
\end{lstlisting}
where the field \texttt{streamBuffer} corresponds to \texttt{[$s_0$,...,$s_p$]} and the field \texttt{streamExpr} to \texttt{e}. Moreover, a simplified definition of the type \texttt{Expr} defined in \texttt{Core.Spec} is :
\begin{lstlisting}[frame=single]
data Expr a where
  Const  :: Type a -> a -> Expr a
  Drop   :: Type a -> DropIdx -> Id -> Expr a
  Op2    :: Op2 a b c -> Expr a -> Expr b -> Expr c
\end{lstlisting}
Then, the translation algorithm is the following. For each stream equation \begin{center}\texttt{ s = [$s_0$,...,$s_p$] ++ e},\end{center}we introduce a new fresh function $f_s$ and the following constraints :

\begin{itemize}
\item $f_s(i) = s_i$ \quad for $1 \leq i \leq p$
\item $\forall n . \; f_s(n + p) = \texttt{expr}_p \; e$
\end{itemize}
where $\texttt{expr}_p$ is defined in this way on expressions :
\begin{itemize}
\item $\texttt{expr}_p \; (\texttt{Const } v) = v$
\item $\texttt{expr}_p \; (\texttt{Drop } g \; i) = f_g(n + p - i)$
\item $\texttt{expr}_p \; (\texttt{Op2 } \oplus \; x_1 \; x_2) =  {expr}_p \; x_1 \; \oplus \; {expr}_p \; x_2 $
\end{itemize}


\paragraph{A formal specification of the IL format} 


An \textbf{IL} specification is given by :
\begin{itemize}
\item Some identifiers for stream functions and some uninterpreted function symbols
\item A list of constraint between stream functions
\item A list of properties, that is boolean stream functions which should be proved to be constant to \texttt{true}.
Constraints are defined by the following grammar.
\end{itemize}

\bigskip

\begin{tabular}{llclr}
& \textbf{constr} & = & \textbf{expr}$_{Bool}$ & \\
$\forall \tau$ & \textbf{expr}$_{\tau}$ & = & $\left< \textit{const}\,_\tau  \right>$ &\\
& & $\textbar$ & \textit{if} \textbf{expr}$_{Bool}$ \textit{then} \textbf{expr}$_{\tau}$ \textit{else} \textbf{expr}$_{\tau}$ \\

& & $\textbar$ &\textbf{op}$^1_{\alpha, \tau}$ \textbf{expr}$_{\alpha}$ \\
& & $\textbar$ & \textbf{expr}$_{\alpha}$ \textbf{op}$^2_{\alpha, \, \beta, \, \tau}$ \textbf{expr}$_{\beta}$ \\
& & $\textbar$ & $\left< \textit{sid} \,  \right> \, \left(\,\textbf{sindex}\,\right)$ \\
& & $\textbar$ & $\left< \textit{unintid} \,  \right> $ $\left(  \exists \alpha . \, \textbf{expr}_\alpha \right)^{*}$
\\
& \textbf{sindex} & = & $\left< \textit{int} \,  \right> $ & \\
& & $\textbar$ & $ \textit{n} +  \left< \textit{int} \,  \right> $ & \\


& $\cdots$ & & \\
&&& \\

& \textbf{op}$^2_{Int, Int, Int}$ & = & $+ \,\textbar \, - \,\textbar\, *  \,\textbar\, mod  \,\textbar\, div  \,\textbar\, \cdots $ & \\
& \textbf{op}$^2_{Int, Int, Bool}$ & = & $< \,\textbar \, \leq \,\textbar\, \geq \,\textbar\, >  \,\textbar\, =  \,\textbar\, \cdots $ & \\
&&& \\
& $\cdots$ & & \\
&&& \\
\end{tabular}

\medskip

Each expression is parametrized by its type, which belongs to $\{
\texttt{Int}, \texttt{Real},  \texttt{Bool}\}$ and is comprised of a
constant, an \textit{if-then-else} construction or other expressions
glued by an operator, or one of the following :

\begin{itemize}
\item The value of a stream at a given time. The grammar for such
a constraint is defined by  an identifier \textit{sid} and an index. The index is either an integer constant or an expression matching the pattern $ \textit{n} +  \left< \textit{int} \,  \right> $, $n$ being an integer variable by which each constraint is implicitly universally quantified.

\item The application of an uninterpreted function, which identifier is given, to a list of arguments.
\end{itemize}
To access a full list of the operators supported by \textit{copilot-kind}, see the module \texttt{Kind.Misc.Operators}.

\subsection{The \textbf{TransSys} format}

Recall, a state transition system is a triple $(S,I,T),$
where $S$ is a set of states, $I \subseteq S$ is the set of initial
states and $T \subseteq S \times S $ is a transition relation over $S$.


Here, a state consists of  the values of a finite set of variables, with types belong to $\{ \texttt{Int}, \texttt{Real},  \texttt{Bool}\}$. $I$ is encoded by a logical formula whose free variables correspond to the state variables and that holds for a state $q$ if and only if $q$ is an initial state. Similarly, the transition relation is given by a formula $T$ such that $T\left[\, q, \, q' \,\right]$ holds if and only if $q \rightarrow q'$. 


The \textbf{TransSys} format is a modular encoding of such a state transition system. Related variables are grouped into \textit{nodes}, each node providing a distinct namespace and expressing some constraints between its variables. 



\paragraph{Formal definition}

Inside a node, a variable is referenced by a string identifier. Indeed, the corresponding \texttt{Var} type is defined as :
\begin{lstlisting}[frame=single]
data Var = Var {varName :: String}
\end{lstlisting}
Outside a node, a variable is referenced by a node identifier and an instance of \texttt{Var} :
\begin{lstlisting}[frame=single]
data ExtVar = ExtVar {extVarNode :: NodeId, extVarLocalPart :: Var} 
\end{lstlisting}
where \texttt{NodeId = String}. Then, the \texttt{Node} type is defined by :
\begin{lstlisting}[frame=single]
data Node = Node
  { nodeId            :: NodeId
  , nodeDependencies  :: [NodeId]
  , nodeLocalVars     :: Map Var VarDescr
  , nodeImportedVars  :: Bimap Var ExtVar 
  , nodeConstrs       :: [Expr Bool] }
\end{lstlisting} 
where :
\begin{itemize}
\item \texttt{nodeId} is the identifier of the node
\item \texttt{nodeImportedVars} contains the bijection between the external variables used in the node and their local aliases. Indeed, inside a node we cannot refer to an external variable (a variable belonging to another node). Therefore, a mean to bind it to a local name is provided.
\item \texttt{nodeDependencies} is the list of the nodes from which a variable is given a local alias. This information is redundant.
\item \texttt{nodeLocalVars} is a dictionnary which binds each local variable to its descriptor. The type of descriptors \texttt{VarDescr} will be described later.
\item \texttt{nodeConstrs} is a list of constraints on local variables.
\end{itemize}
A variable descriptor is comprised  of a type and a definition :
\begin{lstlisting}[frame=single]
data VarDescr = forall t.VarDescr
  { varType :: Type t
  , varDef  :: VarDef t }
\end{lstlisting}
Note that in the same way as in \texttt{Copilot.Core}, {\sc
  gadt}s~\cite{Xi2003,CheneyHinze03, Johann2008} are used to achieve some additional type safety. The \texttt{VarDef} type is defined as :
\begin{lstlisting}[frame=single]
data VarDef t =
    Pre t Var
  | Expr (Expr t)
  | Constrs [Expr Bool]
\end{lstlisting}
As we can see, a local variable can be defined
\begin{itemize}
\item as the previous value of another variable, an initial value being given too (\texttt{Pre} constructor)
\item by an expression involving other variables (\texttt{Expr} constructor)
\item implicitly by a serie of constraints (\texttt{Constrs} constructor)
\end{itemize}
Note that the last constructor can be used to achieve some non-determinism. For instance, a variable whose \texttt{varDef} field is \texttt{Constrs []} is left totally unconstrained~\footnote{In fact, this is not exact as each constraint which is put in a \texttt{Constrs} constructor could have been put in the \texttt{nodeConstrs} field of the current node instead. However, this is to be avoided for readability and the \texttt{nodeConstrs} field should be left empty as often as possible.
}. The expression type associated with the second constructor is defined as :
\begin{lstlisting}[frame=single]
data Expr t where
  Const  :: Type t -> t -> Expr t
  Ite    :: Type t -> Expr Bool -> Expr t -> Expr t -> Expr t
  Op1    :: Type t -> Op1 x t -> Expr x -> Expr t
  Op2    :: Type t -> Op2 x y t -> Expr x -> Expr y -> Expr t
  VarE   :: Type t -> Var -> Expr t
\end{lstlisting}
Therefore, an expression is a combination of constants, operators, and local variable names.


Finally, a specification in the \textbf{TransSys} format is comprised
of  a list of node and a dictionary binding property names to boolean variables which have to be shown constant equals to \texttt{true}.
\begin{lstlisting}[frame=single]
data Spec = Spec
  { specNodes :: [Node]
  , specProps :: Map PropId ExtVar }
\end{lstlisting}


\paragraph{Semantics of a transition system}
We give a semantics to \textbf{TransSys} specifications by extracting from them a state transition system in the form of a list of variables and two boolean formulas $I$ and $T$. 

The list of variables is simply a concatenation of the local variables of all nodes. Then, we define the formula $C$ as the concatenation of the following clauses, for each node :


\begin{itemize}
\item A series of equalities $a_i = b_i$ for each entry $(a_i, b_i)$ in \texttt{nodeImportedVars}
\item Each constraint defined in \texttt{nodeConstrs}
\item For each local variable $v$ defined in \texttt{nodeLocalVars} :

\begin{itemize}
\item If the \texttt{Expr} $e$ constructor is used, add the constraint $v = e$
\item If the \texttt{Constrs cs} constructor is used, add the constraints \texttt{cs} 
\item If the \texttt{Pre} constructor is used, add no constraint
\end{itemize}

\end{itemize}


Then, we define a formula $T_0[\vec q, \vec q \,']$ where $\vec q$ is the vector of variables representing the current state. Moreover, $\vec q \,'$ is a vector containing the same variables, primed, and represents the \textit{next} state. $T_0$ is defined as the conjunction of the following clauses, for each node and each local variable $u$ which descriptor is \texttt{Pre \_} $v$ :
\begin{center} $u' = v$ \end{center}
After this, we define a formula $I_0[\vec q]$ that  is the conjunction of the following clauses, for each node and each local variable $u$ which descriptor is \texttt{Pre} $a$ \_ :
\begin{center} $u = a$ \end{center}
Finally, we define $I$ and $T$ as :
\[  I[\vec q] =  I_0[\vec q] \;\wedge\; C[\vec q] \qquad T[\vec q, \; \vec q \, '] = T_0[\vec q, \; \vec q \,'] \, \wedge \, C[\vec q \, ']  \]




\paragraph{Translation from the \texttt{Core} format to the \texttt{TransSys} format}

This translation process is pretty straightforward : for each stream definition
\begin{center}\texttt{ s = [$s_0$,...,$s_p$] ++ e}\end{center}
we add a node with the same name as $s$ and the local variables $out_0, out_1, \cdots, \, out_p$ with the descriptors :

\begin{itemize}
\item $out_{i} = $  \texttt{Pre} $s_i$  $out_{i + 1}$
\item $out_{p} = $  \texttt{Expr} $\tilde e$  where $\tilde e$ is a translation of $e$ in the \textbf{TransSys} expression format, which is quite similar to the core expression format. Moreover :

\begin{itemize}
\item Local variables in the core format can be expressed by adding variables in the current node.
\item The core expression \texttt{Drop} $g$ $i$ is translated by $out_{p - i}$ if $g = s$. Otherwise, a local alias is defined for the variable $out_{p - i}$ of the node $g$ and is returned.
\end{itemize}

\end{itemize}

\paragraph{Transformations on modular transition systems} 
%The transition system obtained by the previously discuddes translation process is perfectly consistent. However, it can't be directly translated into the Kind2 native file format. Indeed, it is natural to bind each node to a predicate but the Kind2 file format requires that each predicate only uses previously defined predicates. However, some nodes in our transition system could be mutually recursive. 

The modular transition systems obtained after the translation process
defined in the previous paragraph cannot  be printed out in the \texttt{Kind2} native format yet. For instance, some nodes could be mutually dependent whereas \texttt{Kind2} requires its predicates to be cycle-dependence free and written in topological order.


In fact, the actual implementation design is aimed at splitting an otherwise longer and more complex translation process in a series of simple program transformations. These transformations are defined in the \texttt{Kind.TransSys.Transform} module.

\bigskip

One of the most basic transformations is merging  nodes, that is, replacing these nodes by a bigger one which contains the concatenation of their local variables. Some of them might have to be renamed to avoid name conflicts. This renaming process is made easier by the use of a specific monad defined in \texttt{Kind.Misc.Renaming}.

The \texttt{removeCycles} :: \texttt{Spec -> Spec} transformation turns a \texttt{TransSys} specification into the \textit{most modular} specification with the same semantics which is dependence-cycle free. This function relies on the \texttt{mergeNodes} :: \texttt{[NodeId] -> Spec -> Spec} function previously discussed. The \texttt{removeCycles} function computes the strongly connected components of the dependency graph of a specification and merges each one into a single node. The complexity of this process is high in the worst case (the square of the total size of the system times the size of the biggest node), but good in practice as few nodes are to be merged in most practical cases.

Note that, with the \texttt{mergeNodes} function, we can get for free the function
\begin{lstlisting}[frame=single]
inline :: Spec -> Spec
inline spec = mergeNodes [nodeId n | n <- specNodes spec] spec
\end{lstlisting}
which discards all the structure of a modular transition system and turns it into a non-modular transition system with only one node.

\bigskip


Once the dependence-cycles have been discarded in a specification, a last transformation is to be applied before an output in the Kind2 native format can be produced. This transformation, whose signature is  \texttt{complete} :: \texttt{Spec -> Spec}, is a bit technical. To put it in a nutshell, it transforms a specification into a semantically equivalent one such that :

\begin{itemize}
\item The dependency graph is transitive, that is, if A depends of B which depends of C then A depends on C.
\item If a node depends on another one, it defines a local alias for all its variables.
\end{itemize}
This way, it is possible to see a node as a predicate on its variables whose definition makes a call to the predicates associated to the nodes of its dependency list. After this, a translation to the Kind2 native format is only a matter of syntax.

\subsection{Some examples}




\subsubsection{A simple property about the Fibonacci sequence}

The following specification :

\begin{lstlisting}[frame=single]
spec = do
  prop "pos" (fib > 0)

  where
    fib :: Stream Word64
    fib = [1, 1] ++ (fib + drop 1 fib)
\end{lstlisting}
can be translated into this IL specification :
\begin{code}
SEQUENCES
    s0 : Int

MODEL INIT
    s0[0] = 1
    s0[1] = 1

MODEL REC
    s0[n + 2] = s0[n] + s0[n + 1]

PROPERTIES
    'pos' : s0[n] > 0
\end{code}
Then, it is possible to use a SMT solver to prove \textit{"pos"}. For instance, here is the SMTLib code produced for the verification of the induction step :
\begin{code}
<step>  (set-logic QF_UFLIA)
<step>  (declare-fun n () Int)
<step>  (declare-fun s0 (Int) Int)
<step>  (assert (= (s0 (+ n 2)) (+ (s0 (+ n 0)) (s0 (+ n 1)))))
<step>  (assert (= (s0 (+ n 3)) (+ (s0 (+ n 1)) (s0 (+ n 2)))))
<step>  (assert (> (s0 (+ n 0)) 0))
<step>  (push 1)
<step>  (assert (or false (not (> (s0 (+ n 1)) 0))))
<step>  (check-sat)
<step>  (pop 1)
<step>  (assert (= (s0 (+ n 4)) (+ (s0 (+ n 2)) (s0 (+ n 3)))))
<step>  (assert (> (s0 (+ n 1)) 0))
<step>  (push 1)
<step>  (assert (or false (not (> (s0 (+ n 2)) 0))))
<step>  (check-sat)
unsat
<step>  (pop 1)
\end{code}

\bigskip

Otherwise, the original Copilot specification could be translated into a modular transition system (shown here after the \texttt{removeCycles} and \texttt{complete} transformations are applied) :
\begin{code}
NODE 's0' DEPENDS ON []
DEFINES
    out : Int =
        1 -> pre out.1
    out.1 : Int =
        1 -> pre out.2
    out.2 : Int =
        (out) + (out.1)

NODE 'prop-pos' DEPENDS ON [s0]
IMPORTS
    (s0 : out) as 's0.out'
    (s0 : out.1) as 's0.out.1'
    (s0 : out.2) as 's0.out.2'
DEFINES
    out : Bool =
        (s0.out) > (0)

NODE 'top' DEPENDS ON [prop-pos, s0]
IMPORTS
    (prop-pos : out) as 'pos'
    (s0 : out) as 's0.out'
    (s0 : out.1) as 's0.out.1'
    (s0 : out.2) as 's0.out.2'

PROPS
'pos' is (top : pos)
\end{code}
This system is translated into 

\begin{code}
(define-pred s0
  ((out Int)
   (out.1 Int)
   (out.2 Int))
  (init
    (and
      (= out 1)
      (= out.1 1)
      (= out.2
        (+ out out.1))))
  (trans
    (and
      (= (prime out) out.1)
      (= (prime out.1) out.2)
      (= (prime out.2)
        (+ (prime out) (prime out.1))))))

(define-pred prop-pos
  ((out Bool)
   (s0.out Int)
   (s0.out.1 Int)
   (s0.out.2 Int))
  (init
    (and
      (= out
        (> s0.out 0))
      (s0.init s0.out s0.out.1 s0.out.2)))
  (trans
    (and
      (= (prime out)
        (> (prime s0.out) 0))
      (s0.trans s0.out s0.out.1 s0.out.2 (prime s0.out) (prime s0.out.1) (prime s0.out.2)))))

(define-pred top
  ((pos Bool)
   (s0.out Int)
   (s0.out.1 Int)
   (s0.out.2 Int))
  (init
    (prop-pos.init pos s0.out s0.out.1 s0.out.2))
  (trans
    (prop-pos.trans pos s0.out s0.out.1 s0.out.2 (prime pos) (prime s0.out) (prime s0.out.1) (prime s0.out.2))))

(check-prop
  ((pos pos)))
\end{code}



\subsubsection{An example of transformations on transition systems}


Consider the following Copilot specification : 

\begin{lstlisting}[frame=single]
spec :: Spec
spec = do
  prop "prop" (a == c)

  where

    a :: Stream Word64
    a = [1] ++ b
    
    b :: Stream Word64
    b = [1] ++ a

    c :: Stream Word64
    c = [1] ++ c
\end{lstlisting}
Translated to the TransSys format, we get :
\begin{code}
NODE 's2' DEPENDS ON []
DEFINES
    out : Int =
        1 -> pre out.1
    out.1 : Int =
        out

NODE 's1' DEPENDS ON [s0]
IMPORTS
    (s0 : out) as 's0.out'
DEFINES
    out : Int =
        1 -> pre out.1
    out.1 : Int =
        s0.out

NODE 's0' DEPENDS ON [s1]
IMPORTS
    (s1 : out) as 's1.out'
DEFINES
    out : Int =
        1 -> pre out.1
    out.1 : Int =
        s1.out

NODE 'prop-prop' DEPENDS ON [s0, s2]
IMPORTS
    (s0 : out) as 's0.out'
    (s2 : out) as 's2.out'
DEFINES
    out : Bool =
        (s0.out) = (s2.out)

NODE 'top' DEPENDS ON [prop-prop]
IMPORTS
    (prop-prop : out) as 'prop'

PROPS
'prop' is (top : prop)
\end{code}
As we can see, the nodes \textit{'s0'} and \textit{'s1'} are mutually dependent. A call to the \texttt{removeCycles} function merges them :
\begin{code}
NODE 's2' DEPENDS ON []
DEFINES
    out : Int =
        1 -> pre out.1
    out.1 : Int =
        out

NODE 's0-s1' DEPENDS ON []
DEFINES
    s0.out : Int =
        1 -> pre s0.out.1
    s0.out.1 : Int =
        s1.out
    s1.out : Int =
        1 -> pre s1.out.1
    s1.out.1 : Int =
        s0.out

NODE 'prop-prop' DEPENDS ON [s0-s1, s2]
IMPORTS
    (s0-s1 : s0.out) as 's0.out'
    (s2 : out) as 's2.out'
DEFINES
    out : Bool =
        (s0.out) = (s2.out)

NODE 'top' DEPENDS ON [prop-prop]
IMPORTS
    (prop-prop : out) as 'prop'

PROPS
'prop' is (top : prop) 
\end{code}
At least, if we apply the \texttt{complete} function, we get :
\begin{code}
NODE 's2' DEPENDS ON []
DEFINES
    out : Int =
        1 -> pre out.1
    out.1 : Int =
        out

NODE 's0-s1' DEPENDS ON []
DEFINES
    s0.out : Int =
        1 -> pre s0.out.1
    s0.out.1 : Int =
        s1.out
    s1.out : Int =
        1 -> pre s1.out.1
    s1.out.1 : Int =
        s0.out

NODE 'prop-prop' DEPENDS ON [s0-s1, s2]
IMPORTS
    (s0-s1 : s0.out) as 's0.out'
    (s0-s1 : s0.out.1) as 's0.out.1'
    (s0-s1 : s1.out) as 's1.out'
    (s0-s1 : s1.out.1) as 's1.out.1'
    (s2 : out) as 's2.out'
    (s2 : out.1) as 's2.out.1'
DEFINES
    out : Bool =
        (s0.out) = (s2.out)

NODE 'top' DEPENDS ON [prop-prop, s0-s1, s2]
IMPORTS
    (prop-prop : out) as 'prop'
    (s0-s1 : s0.out) as 's0.out'
    (s0-s1 : s0.out.1) as 's0.out.1'
    (s0-s1 : s1.out) as 's1.out'
    (s0-s1 : s1.out.1) as 's1.out.1'
    (s2 : out) as 's2.out'
    (s2 : out.1) as 's2.out.1'

PROPS
'prop' is (top : prop)
\end{code}
At least, if we had used \texttt{inline} instead of \texttt{complete . removeCycles}, we would have gotten :
\begin{code}
NODE 'top' DEPENDS ON []
DEFINES
    prop-prop.out : Bool =
        (s0.out) = (s2.out)
    s0.out : Int =
        1 -> pre s0.out.1
    s0.out.1 : Int =
        s1.out
    s1.out : Int =
        1 -> pre s1.out.1
    s1.out.1 : Int =
        s0.out
    s2.out : Int =
        1 -> pre s2.out.1
    s2.out.1 : Int =
        s2.out

PROPS
'prop' is (top : prop-prop.out)
\end{code}


\subsubsection{The Boyer-Moore majority vote algorithm}

Finally, we study a more ambitious example : the Boyer-moore majority vote algorithm. If not familiar with it, the reader should consult \ref{?} first. Two versions of this algorithm were checked with \texttt{copilot-kind}. The first one comes from the original Copilot tutorial \ref{?} and is a parallel implementation : at each tick, the algorithm takes $n$ inputs from $n$ distinct streams and is fully executed. The second one is a sequential version, where the inputs are delivered one by one in time and where the result is updated at each clock tick. Both can be checked with the basic k-induction algorithm but the proofs involved are of very different natures.


\paragraph{The parallel version}

The core of the algorithm is the following :

\begin{code}
majorityVote :: forall a . (Typed a, Eq a) => [Stream a] -> Stream a
majorityVote [] = error "empty list"
majorityVote (x : xs) = aux x 1 xs
  where
  aux :: Stream a -> Stream Word8 -> [Stream a] -> Stream a
  aux p _s [] = p
  aux p s (l : ls) =
    local (if s == 0 then l else p) $ \ p' ->
    local (if s == 0 || l == p then s + 1 else s - 1) $ \ s' ->
    aux p' s' ls
\end{code}
Let's denote $A$ the set of the elements that can be used as inputs for the algorithm. If $l$ is a list and $a \in A$, we denote $|l|_a$ the number of occurences of $a$ in $l$. The total length of a list $l$ is simply written $|l|$. The \texttt{majorityVote} functions takes a list of streams $l$ as its input and returns an output $maj$ such that : \[ \forall a \in A, \;  \left( a \neq maj \right) \Longrightarrow \left(|l|_a \leq |l| / {2}\right)  \] As said before, quantifiers are handled very poorly by SMT solvers and their use is restricted in most model-checking tools, including \texttt{copilot-kind}. Hopefully, in this case, we can use a very simple trick to write and check this property. Indeed, if $P(n)$ is a predicate of an integer $n$, we have $\forall n, \; P(n)$ if and only if $\neg P(n)$ is satisfiable, where $n$ an unconstrained integer, which can be solved by a SMT solver. Using this trick, the corresponding copilot specification can be written as :
\begin{code}
okWith :: 
  forall a . (Typed a, Eq a) => 
  Stream a -> [Stream a] -> Stream a -> Stream Bool
  
okWith a l maj = (a /= maj) ==> ((2 * count a l) <= length l)
  where
  count :: Stream a -> [Stream a] -> Stream Word8
  count _e [] = 0
  count e (x : xs) = (if x == e then 1 else 0) + count e xs

spec :: Spec
spec = do
  prop "OK" (okWith (arbitraryCst "n") ss maj)
  where
    ss = [ arbitrary ("s" ++ show i) | i <- [1..10]]
    maj = majorityVote
\end{code}
The function \texttt{arbitrary} is provided by the copilot-kind standard library and introduces an arbitrary stream. In the same way, \texttt{arbitraryCst} introduces a stream taking an unconstrained but constant value.

Note that we prove the algorithm for a fixed number of $N$ inputs (here $N=10$). Therefore no induction is needed for the proof and the invariant of the Boyer-Moore algorithm doesn't need to be made explicit. However, the size of the problem discharged to the SMT solver grows in proportion to $N$.


\paragraph{The serial version} Now, we discuss an implementation of the algorithm where the inputs are read one by one in a single stream and the result is updated at each clock tick. As the number of inputs of the algorithm isn't bounded anymore, a proof by induction is necessary and the invariant of the Boyer-Moore algorithm, being non-trivial, have to be stated explicitly. As seen in \ref{?}, this invariants is :
\[ \begin{array}{c}
\forall m \in A, \;\;\; \left(m \neq p\right) \Longrightarrow \left( s + 2|l|_m \,\leq\, |l| \right) \;\; \wedge \;\; \left(m = p\right) \Longrightarrow \left( 2|l|_m \,\leq\, s + |l| \right)
\\

\end{array} \]
where $l$ is the list of processed inputs, $p$ is the intermediary result and $s$ is an internal state of the algorithm. The problem here is that the induction invariant needs universal quantification to be expressed. Unfortunately, this quantifier can't be removed by a similar trick like the one seen previously. Indeed, when an invariant is of the form $\forall x. P(x, s)$, $s$ denoting the current state of the world, the induction formula we have to prove is :
\[ \forall x. P(x, s) \,\wedge\, T\left(s, s' \right) \,\models\, \forall x. P(x, s') \]
Sometimes, the stronger entailment 
\[ P(x, s) \,\wedge\, T\left(s, s' \right) \,\models\, P(x, s') \]
holds and the problem becomes tractable for the SMT solver, by replacing a universally quantified variable by an unconstrained one. In our current example, it is not the case. 


The way we fix this is far from being perfect : we restrains ourselves to the case where $A$ is finite and replace each formula of the form $\forall x \in A \; P(x)$ by $\bigwedge_{x \in A} P(x)$. This can be done with the help of the \texttt{forAllCst} function provided by the copilot-kind standard library. It is defined as :
\begin{code}
forAllCst ::(Typed a) => [a] -> (Stream a -> Stream Bool) -> Stream Bool
forAllCst l f = conj \$ map (f . constant) l
  where conj = foldl (&&) true
\end{code}
The code for the serial Boyer-Moore algorithm and its specification is then :

\begin{code}
allowed :: [Word8]
allowed = [1, 2]

majority :: Stream Word8 -> (Stream Word8, Stream Word8, Stream Bool)
majority l = (p, s, j)
  where
    p  = [0] ++ if s <= 0 then l else p
    s  = [0] ++ if p == l || s <= 0 then s + 1 else s - 1
    k  = [0] ++ (1 + k)
    
    count m = cnt
      where cnt = [0] ++ if l == m then cnt + 1 else cnt
    
    j = forAllCst allowed \$ \ m ->
          local (count m) \$ \ cnt ->
          let j0 = (m /= p) ==> ((s + 2 * cnt) <= k)
              j1 = (m == p) ==> ((2 * cnt) <= (s + k))
          in j0 && j1

spec = do
  prop "J" j
  prop "inRange" (existsCst allowed \$ \ a -> input == a)
  where
    input = externW8 "in" Nothing
    (p, s, j) = majority input

scheme = do
  assuming ["inRange"] \$ check "J"
\end{code}
As the reader can see, we make the hypothesis that all the elements manipulated by the algorithm are in the set \texttt{allowed}, which is finite. As this set grows, the proofs discharged to the SMT solver becomes more and more large and redundant, which is why this solution isn't scalable and has limited real world interest.




