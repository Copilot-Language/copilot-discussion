\section{Advanced Topics} \label{sec:advanced}

Here we discuss more in depth topics within the Copilot Language. These topics
are not necessary to gain a basic understanding of the language, but they are 
helpful as a reference and for more in depth understanding. 

\subsection{Proofs of Monitors}~\label{subsec:proof}

In addition to proofs on the soundness of the Copilot compilation process, we
also support (in the {\tt Copilot.Theorem} module) some automated proving of
safety properties about Copilot specifications themselves. A proposition is a
Copilot value of type \lstinline{Prop Existential} or \lstinline{Prop Universal},
 which can be introduced using \lstinline{exists} and
\lstinline{forall}, respectively. These are functions taking as an argument a
normal Copilot stream of type \lstinline{Stream Bool}. Propositions can be added
to a specification using the \lstinline{prop} and \lstinline{theorem} functions,
where \lstinline{theorem} must also be passed a tactic for autmatically proving
the proposition. Consider this Copilot monitor specification for a version of
the fibonacci sequence:

\begin{lstlisting}[language = Copilot]
module Fib where

import Prelude ()
import Copilot.Language
import Copilot.Language.Reify
import Copilot.Theorem
import Copilot.Theorem.Prover.SMT

fib = do
  theorem "fibn_gre_n" (forall $ fibn >= n) $ kInduction def cvc4

  observer "fibn" fibn
  observer "n"    n
  where
    fibn :: Stream Word32
    fibn = [1, 1] ++ (fibn + drop 1 fibn)
    n = [0] ++ (n + 1)
\end{lstlisting}

In the specification above, in addition to observing the value of streams in
the specification, \lstinline{fibn_gre_n} names a theorem provable
automatically with induction using the Z3 SMT solver. This theorem can be
checked during reification:

\begin{code}
*Fib> reify fib
fibn_gre_n: valid (proved with k-induction (k = 3))
Finished: fibn_gre_n: proof checked successfully
\end{code}

The {\tt Copilot.Theorem} module provides two main mechanisms for interacting
with SMT solver backends: a generic backend at {\tt Copilot.Theorem.Prover.SMT}
that nominally supports a wide range of SMT solvers and {\tt
Copilot.Theorem.Prover.Z3}, a backend specialized to Z3. The example above uses
the generic {\tt SMT} backend with the CVC4 SMT solver.

See Figure~\ref{fig:solvers} for an overview of SMT solvers that have at least
been tested to work with our tool. The second column contains the value of type
{\tt Backend} from the {\tt Copilot.Theorem.Prover.SMT} module which must be
passed to the tactics in this module for executing the tactic using that SMT
solver (e.g., as is done in the second argument to {\tt kInduction} in the
example above). To use a certain SMT solver, the solver must be installed and
the executable should reside in one of the directories listed in the {\tt
\$PATH} environment variable.

\newcommand{\Yes}{\checkmark}
\newcommand{\No}{\textsf{X}}
\newcommand{\Some}{\textsf{Some}}

\begin{figure}
\begin{center}
\begin{tabular}{llllcccc}
Tool       & {\tt Backend} & Version & Interface & NL Real Arith.\ & Trig.\ funs.\ & Quantif. & Bitvec. \\
\toprule
Alt-Ergo   & {\tt altErgo} & 0.99.1  & SMTLib2   & \Yes{}          & \No{}         & \Yes{}      & \No{}      \\
CVC4       & {\tt cvc4}    & 1.4     & SMTLib2   & \Some{}         & \No{}         & \Yes{}      & \Yes{}     \\
DReal      & {\tt dReal}   & 2.15.01 & SMTLib2   & \Yes{}          & \Yes{}        & \No{}       & \No{}      \\
MathSAT    & {\tt mathSat} & 5.3.7   & SMTLib2   & \Some{}         & \No{}         & \No{}       & \Yes{}     \\
MetiTarski & {\tt metit}   & 2.5     & TPTP      & \Yes{}          & \Yes{}        & \Yes{}      & \No{}      \\
Yices      & {\tt yices}   & 2.4.0   & SMTLib2   & \Some{}         & \No{}         & \No{}       & \Yes{}     \\
Z3         & {\tt z3}      & 4.4.0   & SMTLib2   & \Yes{}          & \No{}         & \Yes{}      & \Yes{}     \\
\end{tabular}
\end{center}
\caption{An overview of some supported SMT solvers.}
\label{fig:solvers}
\end{figure}

As seen in the figure mentioned above, different SMT solvers have different
feature sets and the methods for using the various features are generally not
well standardized. As a result, we also have backend specialized to Z3, one of
the more feature-rich SMT solvers we've tested. The example above using the Z3
backend looks very similar to the version above:

\begin{lstlisting}[language = Copilot]
module Fib where

import Prelude ()
import Copilot.Language
import Copilot.Language.Reify
import Copilot.Theorem
import Copilot.Theorem.Prover.Z3

fib = do
  theorem "fibn_gre_n" (forall $ fibn >= n) $ kInduction def

  observer "fibn" fibn
  observer "n"    n
  where
    fibn :: Stream Word32
    fibn = [1, 1] ++ (fibn + drop 1 fibn)
    n = [0] ++ (n + 1)
\end{lstlisting}

Instead of importing {\tt Copilot.Theorem.Prover.SMT}, we import {\tt
Copilot.Theorem.Prover.Z3}, and we no longer need to pass the {\tt cvc4}
argument to {\tt kInduction} (because the SMT solver backend will be Z3). But
now when we go to reify {\tt fib}:

\begin{code}
*Fib> reify fib
fibn_gre_n: unknown (proof by k-induction failed)
Finished: fibn_gre_n: proof failed
Warning: failed to check some proofs.
\end{code}

This demonstrates an important limitation of the {\tt
Copilot.Theorem.Prover.SMT} backend: it encodes fixed-width integers using the
SMTLib {\tt Int} type (with some extra propositions about the bounds of {\tt
Int} variables)---it {\em does not model overflow}. The {\tt
Copilot.Theorem.Prover.Z3} backend, however, encodes Copilot's fixed-width
integer types using Z3's bitvectors. Now if we allow {\tt fibn} to overflow, the
theorem from the above example is clearly not true.

The above example contains a single {\tt theorem}. A {\tt theorem} takes three
arguments: the name of the theorem (which is only used to identify the theorem
in output), a proposition, and a proof ``tactic'' to use when trying to
automatically prove the proposition using SMT solvers. The {\tt
Copilot.Theorem.Prover.SMT} and {\tt Copilot.Theorem.Prover.Z3} modules both
export the same set of tactics\footnote{In fact, these modules share a lot a
duplicated code and desparately need to be refactored.}:
\begin{itemize}
\item {\tt onlySat}: check that the proposition is satisfiable.
\item {\tt onlyValidity}: check that the negation of the proposition is
unsatisfiable.
\item {\tt induction}: special case of $k$-induction, with $k = 0$.
\item {\tt kInduction}: version of induction where the induction hypothesis is
strengthened by including $k$ previous states.
\end{itemize}

Additionally, a few other tactics live in {\tt Copilot.Theorem.Tactics}:
\begin{itemize}
\item {\tt instantiate}: turn a proof for a universally quantified proposition
into a proof for an existentially quantified one.
\item {\tt assume}: prove a proposition true under an assumption.
\item {\tt admit}: prove anything.
\end{itemize}

Also, we support some older versions of the Kind2 model checker.

\subsection{Correctness of the generated code}~\label{sec:correctness}

\subsubsection{Frama-c}~\label{subsec:frama-c}
For this, make sure the following is installed:

\begin{itemize}
	\item GNU parallel
	\item frama-c (version at least sodium)
	\item why3
	\item cvc4 prover
\end{itemize}

It is possible to generate C code optimized for frama-c by using the \texttt{proofACSL}
function from SBV.Compile (instead of \texttt{compile} as shown
in~\ref{sec:compiling}). It will then generate the C source code (which should be in
the \texttt{copilot-sbv-codegen} folder). Go into that folder and just run
\texttt{make fwp} to use frama-c with the WP plugin. This should generate two
log files: a first exhaustive one called \texttt{logfwp}, and another which
summaries the former which is called \texttt{logfwpcompact}. The command make
fwp is detailed in Figure~\ref{fig:fwp}.

\begin{figure*}[!htb]
	\begin{lstlisting}[frame=none, language=bash]
parallel frama-c -wp -wp-out . -wp-timeout 20 -wp-prover CVC4 -wp-split {} ::: *.c | tee >logfwp >(grep 'Proved\|Unknown\|Timeout\|Failed\|Qed:\s\|CVC4:\s\|Parsing .*\.c' > logfwpcompact) >(grep 'Proved\|Qed:\s\|CVC4:\s\|Unknown\|Timeout\|Failed\|Parsing .*\.c')

	\end{lstlisting}
	\caption{The bash command.}
	\label{fig:fwp}
\end{figure*}

It is also possible to run frama-c with the value analysis plugin by running
\texttt{make fval}. Be careful, the value analysis plugin requires to preload
all the C sources files together, which requires a lot of RAM memory for big
projects.

It is recommended to refactor your code before trying to use frama-c on it, by for example splitting non-trivial expressions using magic labels, deleting all
local variables (use functions) and bitwise operators. If this step is
neglected, it may happen that frama-c would start swapping all your memory
resulting in a system crash.

\subsubsection{Splint}~\label{subsec:splint}

If you have splint installed on your computer, you can also try running splint on the C source code generated (with the command \texttt{make splint}), which will be a good starting point for manual code optimization or refactoring. The same problem as for frama-c may occur if you are working on a very big project (system crash).

\textbf{This tools does not guarantee that the generated C source code is compliant to ISO 9899:1999.} 

\subsubsection{Dot}~\label{subsec:dot}

It is also possible to generate dot graphs for each C source file generated, in
order to make the files more understandable. For this, you should check that
you have dot installed. Extract the dot code from a C source file, and then
just run \texttt{dot -Tps code.gv -o code.ps}
%
\footnote{A script doing that automatically is provided here
\url{https://raw.githubusercontent.com/Copilot-Language/examplesForACSL/master/WCV/scriptdot.cpp}}.

\subsection{Compiling process}

The Haskell source file is then compiled using the SBV backend. The file is first preprocessed using m4 into an other Haskell file with all constants replaced by their appropriate values. Then, after parsing, we obtain a first AST that is then reified to a core AST (some beta reduction are done), using standard reification techniques in \cite{Copilot06}. Then some AST transformers that keep the semantics are applied, transforming some operands that do not exist in SBV into expressions with only operators with SBV (recip, abs, ...). After this, we first transform the AST into an other one used by SBV, and in the process we generate both ACSL source code and DOT code. This means that the SBV AST contains "decorative" nodes that contain a ACSL or DOT code describing the child AST (TODO modify expression). 

This nodes are then converted into comments into the C sources files that are then checked against the source code generated for the child AST with frama-c wp plugin. This helps us increase the confidence in the compilation process, by checking two different techniques (pretty printing and compilation) each against the other, hence reducing the probability that a similar bug is present both in the pretty printer (which generates the ACSL contracts) and the SBV compiler. Moreover, the same Haskell that has been written at top level has been checked with Metitarski after the m4 expansion. This can be shown by the following Figure~\ref{fig:WCVprocess} :


\begin{figure}[hbt!]
	\centering
	\footnotesize
	\begin{tikzpicture}[->, node distance=3cm, auto, shorten >=1pt, bend angle=45,
	thick]
	\tikzstyle{every state}=[rectangle, rounded corners]
	
	\node[state] (Lang) {%
		\begin{tabular}[b]{l}
		Copilot.Language AST
		\end{tabular}};
	
	\node[state] (M5) [left=1.8cm of Lang] {\begin{tabular}[b]{l}
		Preprocessed\\ Haskell
		\end{tabular}};
	\node[state] (M4) [below=1cm of M5] {Haskell};
	\node[state] (RR) [below right of=Lang] {Reified AST};
	\node[state] (Core) [below=0.3cm of RR] {Copilot.Core AST};
	
	
	\node[state] (ACSL) [below right= 2cm of Core] {\begin{tabular}[b]{l}
		ACSL\\ code
		\end{tabular}};
	\node[state] (DOTc) [right of=ACSL] {\begin{tabular}[b]{l}
		DOT\\ code
		\end{tabular}};
	\node[state] (SBV) [below of=Core] {SBV AST};
	\node[state] (C99S) [below of=SBV] {\begin{tabular}[b]{l}
		DOT\\ \hline ACSL\\ \hline C99
		\end{tabular}};
	\node[state] (DOT) [below right of=C99S] {DOT/graphviz};
	\node[state] (SMT) [left=3cm of SBV] {SMTLib code};
	\node[state] (ASM) [below left of= C99S] {Assembly code};
	
	
	\tikzstyle{every node}=[]
	
	
	\path %% (Libs) edge node {0,1,L} (Lang);
	%% edge node {1,1,R} (C)
	(Lang) edge [bend left, anchor=west, text width=2.5cm] node {Reification and DSL-specific type-checking} (RR)
	(RR) edge [anchor=west, text width=2.5cm] node {} (Core)
	%% edge node {0,1,L} (C)
	(M4) edge [text width=2.5cm, anchor = west] node {Preprocessing with m4} (M5)
	(M5) edge [text width=1.5cm] node {Parsing} (Lang)
	(Core) edge [anchor=east] node {Translation} (SBV)
	(ACSL) edge [bend left, anchor=west] node {Integration} (C99S)
	(DOTc) edge [bend left, anchor=east] node {} (C99S)
	(Core) edge [->, anchor=north, text width=3cm] node {ACSL generation} (ACSL)
	(Core) edge [->, anchor=west] node {DOT generation} (DOTc)
	(RR) edge [bend right, ->, anchor=north east,text width=4cm] node {SMTlib generation of high level properties} (SMT)
	(SMT) edge [loop below, ->, anchor=north,text width=4cm] node {Verification with an SMT solver (Z3,...)} (SMT)
	(C99S) edge [->, anchor=east] node {Cross-compilation} (ASM)
	(C99S) edge [loop left, ->, anchor=east] node {Verification with frama-c WP plugin} (C99S)
	(C99S) edge [->, anchor=west] node {Extraction and graph generation} (DOT)
	(SBV) edge [->,anchor=east] node {Compilation} (C99S);
	%% edge [bend left] node {Translation} (SBV)
	%% (Atom) edge [loop below] node {1,1,R} (D)
	%% edge node {0,1,R} (Libs)
	%% (SBV) edge [bend left] node {1,0,R} ();
	\end{tikzpicture}
	\caption{The whole process of WCV compilation.}
	\label{fig:WCVprocess}
\end{figure}

\begin{figure}[hbt!]
	\centering
	\footnotesize
	\begin{tikzpicture}[->, node distance=2.3cm, auto, shorten >=1pt, bend angle=45,thick]
	\tikzstyle{every state}=[rectangle, rounded corners]
	
	\node[state] (Plane) {Planes};
	\node[state] (GUI) [right of=Plane] {GUI};
	\node[state] (Mon) [right=2cm of GUI] {monitor.c};
	\node[state] (dr) [right of=Mon] {driver.c};
	\node[state] (ex) [above right of=Mon] {external};
	
	
	\node[state] (AL) [below of=GUI] {ALERT};
	\node[state] (Co) [below of=Mon] {Converter};
	
	
	\tikzstyle{every node}=[]
	
	
	\path
	(Plane) edge node {UDP} (GUI)
	(GUI) edge [bend right] node {stdin} (Mon)
	(Mon) edge [bend right] node {stdout} (GUI)
	(Mon) edge [bend left, anchor=west] node {lat-long} (Co)
	(Co) edge [bend left, anchor=west] node[left] {x,y,z} (Mon)
	(Mon) edge [anchor=west] node {assign} (ex)
	(Mon) edge [anchor=south] node {call} (dr)
	(ex) edge [anchor=west] node {feed} (dr)
	(GUI) edge node {} (AL);
	\end{tikzpicture}
	\caption{The ground station monitor structure}.
	\label{fig:gss}
\end{figure}

Then we made it comply to real application with the following scheme in Figure~\ref{fig:gss} :
\begin{itemize}
	\item The planes send raw data via UDP network system in the form of lat-long-alt, tgs, hdg, vspeed.
	\item All these data are collected by a GUI, that has the role of sending these data to the monitor, and getting back the monitor's data to show if any alert has been raised (the role of the GUI is to make the sound, or blink LEDs everywhere in the ALERT module).
	\item The monitor.c is a c file that can receive 3 different instructions :
	\subitem A new plane entered in the control area (ICAO24 given)
	\subitem A plane is leaving the area (with ICAO24 given)
	\subitem A plane is updating its coordinates (ICAO24 + lat-long-alt-hdg-tgs-vertical speed format). In this case, the plane is converting the coordinates into classical x,y,z with the Converter (TODO : put the real coordinates system somewhere). And then for all planes, it checks if this plane is in a WCV conflit with it (using the driver.c generated by Copilot). If yes, it raises an alert on stdout for every plane that is in conflict. 
\end{itemize}

\subsection{Cross compiling}~\label{sec:cross}

If you go in the \texttt{copilot-sbv-codegen} folder, and run {\tt make all}
inside it, it should generate an archive file named \texttt{internal.a}, using
the compiler defined in the file \texttt{copilot.mk} (default is compcert, you
have to install it with its standard library). This can create some problems
during the linking process if you change the compiler for the final compilation
(typically \texttt{gcc -m32 -lm main.c internal.a} where \texttt{main.c} is
where your controller code is). For this purpose, we recommend installing first
the cross compiler (example \texttt{arm-none-eabi-gcc}), and compile the
\emph{whole} project using that very same compiler using the command \texttt{arm-none-eabi-gcc -m32 -lm [options] *.c}.
